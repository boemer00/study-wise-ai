{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2049af3-aa08-447d-b24c-b2c21ef6dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install & import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0857404b-d0f9-48a0-9b5e-fa804c475df8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:50:09.709003Z",
     "iopub.status.busy": "2025-05-21T14:50:09.708248Z",
     "iopub.status.idle": "2025-05-21T14:50:09.759209Z",
     "shell.execute_reply": "2025-05-21T14:50:09.758817Z",
     "shell.execute_reply.started": "2025-05-21T14:50:09.708931Z"
    }
   },
   "outputs": [],
   "source": [
    "import fitz                    \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4d2b5f-36a0-4b69-bc6c-9a06e55e0c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:20:44.122865Z",
     "iopub.status.busy": "2025-05-21T14:20:44.122381Z",
     "iopub.status.idle": "2025-05-21T14:20:44.126939Z",
     "shell.execute_reply": "2025-05-21T14:20:44.126355Z",
     "shell.execute_reply.started": "2025-05-21T14:20:44.122819Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268dfb2d-3700-4357-b2d1-d58f77b307e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:33:09.436686Z",
     "iopub.status.busy": "2025-05-21T14:33:09.435783Z",
     "iopub.status.idle": "2025-05-21T14:33:09.539056Z",
     "shell.execute_reply": "2025-05-21T14:33:09.538657Z",
     "shell.execute_reply.started": "2025-05-21T14:33:09.436639Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = fitz.open(\"attention_is_all_you_need.pdf\")\n",
    "raw_text = \"\\n\\n\".join(page.get_text(\"text\") for page in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77908ed7-13a9-4874-a220-2b4d992de029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:35:03.109979Z",
     "iopub.status.busy": "2025-05-21T14:35:03.108955Z",
     "iopub.status.idle": "2025-05-21T14:35:03.117002Z",
     "shell.execute_reply": "2025-05-21T14:35:03.116048Z",
     "shell.execute_reply.started": "2025-05-21T14:35:03.109907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Attention Is All You Need'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[174:199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74a3e55-1016-42f9-903c-8601efdafb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Chunk the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2da921cf-e739-4acc-921d-ef7ee8991282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:36:29.937255Z",
     "iopub.status.busy": "2025-05-21T14:36:29.936677Z",
     "iopub.status.idle": "2025-05-21T14:36:29.945599Z",
     "shell.execute_reply": "2025-05-21T14:36:29.945043Z",
     "shell.execute_reply.started": "2025-05-21T14:36:29.937210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 52 chunks.\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(raw_text)\n",
    "print(f\"Generated {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b208c32d-5738-4c6e-a154-bf2153155f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. (Optional) Embed & store in Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71736025-749b-4b90-b25a-0665a8d61e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:51:36.058754Z",
     "iopub.status.busy": "2025-05-21T14:51:36.058046Z",
     "iopub.status.idle": "2025-05-21T14:51:42.448394Z",
     "shell.execute_reply": "2025-05-21T14:51:42.445346Z",
     "shell.execute_reply.started": "2025-05-21T14:51:36.058701Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Flashcard‐generation prompt\n",
    "client = OpenAI()\n",
    "\n",
    "level = [beginner, intermediate, advanced, expert]\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a data‐science tutor generating flashcards for a {level[2]}.\n",
    "Context:\n",
    "\\\"\\\"\\\"\n",
    "{chunks[0:5]}\n",
    "\\\"\\\"\\\"\n",
    "Output JSON array of objects with \"question\" and \"answer\" fields.\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=[{\"role\": \"developer\",\n",
    "            \"content\": \"You are an expert tutor who know exactly what students need to learn.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": prompt}],\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "cards = response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0997b87b-9161-4bf8-80cb-2dab0ff6d346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:51:42.455015Z",
     "iopub.status.busy": "2025-05-21T14:51:42.454309Z",
     "iopub.status.idle": "2025-05-21T14:51:42.464365Z",
     "shell.execute_reply": "2025-05-21T14:51:42.459675Z",
     "shell.execute_reply.started": "2025-05-21T14:51:42.454971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"question\": \"What is the main innovation introduced by the Transformer model?\",\\n    \"answer\": \"The Transformer model is based solely on attention mechanisms, completely dispensing with recurrence and convolutions.\"\\n  },\\n  {\\n    \"question\": \"Why is the Transformer model considered more efficient than previous models?\",\\n    \"answer\": \"The Transformer is more parallelizable and requires significantly less time to train compared to models based on recurrent or convolutional neural networks.\"\\n  },\\n  {\\n    \"question\": \"What tasks did the Transformer model outperform previous models on?\",\\n    \"answer\": \"The Transformer outperformed previous models on machine translation tasks, specifically on the WMT 2014 English-to-German and English-to-French translation tasks.\"\\n  },\\n  {\\n    \"question\": \"What BLEU scores did the Transformer achieve on the WMT 2014 translation tasks?\",\\n    \"answer\": \"The Transformer achieved a BLEU score of 28.4 on English-to-German and 41.8 on English-to-French translation tasks.\"\\n  },\\n  {\\n    \"question\": \"What are some limitations of recurrent neural networks (RNNs) in sequence modeling?\",\\n    \"answer\": \"RNNs are inherently sequential, which precludes parallelization within training examples and makes training slower, especially for long sequences.\"\\n  },\\n  {\\n    \"question\": \"How does the Transformer model connect the encoder and decoder?\",\\n    \"answer\": \"The Transformer connects the encoder and decoder through an attention mechanism.\"\\n  },\\n  {\\n    \"question\": \"What is the significance of the Transformer model for tasks beyond translation?\",\\n    \"answer\": \"The Transformer generalizes well to other tasks, such as English constituency parsing, even with limited training data.\"\\n  },\\n  {\\n    \"question\": \"What is the main drawback of using RNNs for sequence transduction tasks?\",\\n    \"answer\": \"RNNs require sequential computation, which limits parallelization and slows down training, especially for long sequences.\"\\n  },\\n  {\\n    \"question\": \"Who are some of the key contributors to the development of the Transformer model?\",\\n    \"answer\": \"Key contributors include Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin.\"\\n  },\\n  {\\n    \"question\": \"What is the title of the paper that introduced the Transformer model?\",\\n    \"answer\": \"The title of the paper is \\'Attention Is All You Need.\\'\"\\n  }\\n]'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50f2624c-1ae0-4eb6-8691-e9372d1f73fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:53:19.656738Z",
     "iopub.status.busy": "2025-05-21T14:53:19.656231Z",
     "iopub.status.idle": "2025-05-21T14:53:19.663019Z",
     "shell.execute_reply": "2025-05-21T14:53:19.662132Z",
     "shell.execute_reply.started": "2025-05-21T14:53:19.656699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2416"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acffb83-187f-4bc5-9e1e-3547337058d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a45bcc-e9ad-4bea-a43b-461a71b168e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
